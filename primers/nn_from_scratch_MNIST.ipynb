{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network From Scratch\n",
    "\n",
    "Simply implementing a Feed-Forward Neural Network From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some libraries\n",
    "import time\n",
    "import operator\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.datasets import mnist # cheating a little, loading easy mnist dataset from keras library\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy.special import expit # more robust sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 784\n",
      "Output: 10\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalize Pixel Values\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# Convert array of ints (digit values) to one-hot encoded categorical\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# convert images from 28x28 to 1x784\n",
    "X_train = np.reshape(X_train, (60000, 784))\n",
    "X_test = np.reshape(X_test, (10000, 784))\n",
    "\n",
    "# get validation set - essentially split test in half\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "print(\"Input:\", X_train.shape[1])\n",
    "print(\"Output:\", y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Useful Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some functions\n",
    "\n",
    "# Activation Function\n",
    "def activation(x, derivative=False):\n",
    "    return relu(x, derivative=derivative)\n",
    "\n",
    "def tanh(x, derivative=False):\n",
    "    return 1 - np.power(x, 2) if derivative else np.tanh(x)\n",
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "    return x * (1 - x) if derivative else expit(x)\n",
    "\n",
    "def relu(x, derivative=False):\n",
    "    return (x>0).astype(x.dtype) if derivative else np.maximum(x, 0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    return np.apply_along_axis(_softmax, 1, x)\n",
    "\n",
    "def _softmax(x):\n",
    "    exps = np.exp(x - np.max(x))\n",
    "    return exps / np.sum(exps)    \n",
    "\n",
    "def calculate_loss(model):\n",
    "    # Computes loss for train and validation sets\n",
    "    W1, b1, W2, b2= model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    \n",
    "    # Train Forward propagation train to calculate our predictions \n",
    "    l1 = activation(X_train.dot(W1) + b1) # Input -> Hidden 1 || activation(x.t * W + bias) \n",
    "    output_train = softmax(l1.dot(W2) + b2) # Hidden 1 -> Output || Softmax Probabilites\n",
    "    \n",
    "    # Validation Forward propagation train to calculate our predictions \n",
    "    l1 = activation(X_val.dot(W1) + b1) # Input -> Hidden 1 || activation(x.t * W + bias) \n",
    "    output_val = softmax(l1.dot(W2) + b2) # Hidden 1 -> Output || Softmax Probabilites\n",
    "    \n",
    "    # Calculating the loss\n",
    "    return log_loss(y_train, output_train), log_loss(y_val, output_val)\n",
    "\n",
    "def get_mini_batches(X, y, batch_size):\n",
    "    random_idxs = np.random.choice(len(y), len(y), replace=False)\n",
    "    X_shuffled = X[random_idxs,:]\n",
    "    y_shuffled = y[random_idxs]\n",
    "    mini_batches = [(X_shuffled[i:i+batch_size,:], y_shuffled[i:i+batch_size]) for\n",
    "                   i in range(0, len(y), batch_size)]\n",
    "    return mini_batches\n",
    "\n",
    "def drop_connect_mask(prob, dimensions):\n",
    "    mask_vector = np.random.binomial(1, prob, np.prod(dimensions))\n",
    "    return mask_vector.reshape(dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Params and Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some parameters\n",
    "\n",
    "# Layer Parameters\n",
    "num_examples = X_train.shape[0] # training set size (60000)\n",
    "nn_input_dim = X_train.shape[1] # input layer dimensionality (784)\n",
    "nn_hdim_1 = 50\n",
    "nn_output_dim = y_train.shape[1] # output layer dimensionality (10)\n",
    "\n",
    "# Gradient descent parameters\n",
    "epochs = 2000 # How many times to forward and back propigate the network\n",
    "learning_rate = .001 # learning rate for gradient descent\n",
    "decay = learning_rate / epochs # Default recommended by this blog post (https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/)\n",
    "reg_lambda = 0 # regularization strength\n",
    "drop_connect_prob = .3 # Probability to drop weight for DropConnect\n",
    "batch_size = 128 # size of batches for minibatch gradient descent\n",
    "print_loss = 20  # prints loss (and checks for early stopping) in some number of epochs\n",
    "stop_threshold = 10  # threshold for early stopping using generalization error\n",
    "\n",
    "# Constants for Adam Optimization (values are paper recommended values)\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "eps = 1E-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 50)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input -> Hidden 1\n",
    "W1 = np.random.randn(nn_input_dim, nn_hdim_1).astype(np.float32)\n",
    "mW1 = np.zeros_like(W1)  # first-moment vector Adam Optimziation for W1\n",
    "vW1 = np.zeros_like(W1)  # second-moment vector Adam Optimization for W1\n",
    "b1 = np.zeros((1, nn_hdim_1))\n",
    "\n",
    "# Hidden 1 -> Output\n",
    "W2 = np.random.randn(nn_hdim_1, nn_output_dim).astype(np.float32)\n",
    "mW2 = np.zeros_like(W2)  # first-moment vector Adam Optimziation for W2\n",
    "vW2 = np.zeros_like(W2)  # second-moment vector Adam Optimization for W2\n",
    "b2 = np.zeros((1, nn_output_dim))\n",
    "\n",
    "W1.shape # for each node in input, there is a weight that corresponds with a node in hidden layer 1 (23520 total weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 1 -> Train: 15.871302, Validation: 15.777674\n",
      "\t- Generalization Loss: -99.842223\n",
      "Loss after iteration 20 -> Train: 2.513429, Validation: 2.487382\n",
      "\t- Generalization Loss: -84.234799\n",
      "Loss after iteration 40 -> Train: 0.994463, Validation: 0.998963\n",
      "\t- Generalization Loss: -59.838783\n",
      "Loss after iteration 60 -> Train: 0.676127, Validation: 0.668722\n",
      "\t- Generalization Loss: -33.058416\n",
      "Loss after iteration 80 -> Train: 0.546766, Validation: 0.546322\n",
      "\t- Generalization Loss: -18.303453\n",
      "Loss after iteration 100 -> Train: 0.473875, Validation: 0.472560\n",
      "\t- Generalization Loss: -13.501721\n",
      "Loss after iteration 120 -> Train: 0.434629, Validation: 0.425277\n",
      "\t- Generalization Loss: -10.005689\n",
      "Loss after iteration 140 -> Train: 0.395713, Validation: 0.384125\n",
      "\t- Generalization Loss: -9.676515\n",
      "Loss after iteration 160 -> Train: 0.358005, Validation: 0.351111\n",
      "\t- Generalization Loss: -8.594613\n",
      "Loss after iteration 180 -> Train: 0.325660, Validation: 0.325391\n",
      "\t- Generalization Loss: -7.325269\n",
      "Loss after iteration 200 -> Train: 0.308759, Validation: 0.312731\n",
      "\t- Generalization Loss: -3.890747\n",
      "Loss after iteration 220 -> Train: 0.284431, Validation: 0.291197\n",
      "\t- Generalization Loss: -6.885656\n",
      "Loss after iteration 240 -> Train: 0.272296, Validation: 0.283695\n",
      "\t- Generalization Loss: -2.576308\n",
      "Loss after iteration 260 -> Train: 0.256182, Validation: 0.271590\n",
      "\t- Generalization Loss: -4.266962\n",
      "Loss after iteration 280 -> Train: 0.245772, Validation: 0.264735\n",
      "\t- Generalization Loss: -2.523875\n",
      "Loss after iteration 300 -> Train: 0.229095, Validation: 0.255872\n",
      "\t- Generalization Loss: -3.347970\n",
      "Loss after iteration 320 -> Train: 0.220404, Validation: 0.253516\n",
      "\t- Generalization Loss: -0.920866\n",
      "Loss after iteration 340 -> Train: 0.217260, Validation: 0.246931\n",
      "\t- Generalization Loss: -2.597473\n",
      "Loss after iteration 360 -> Train: 0.211512, Validation: 0.252362\n",
      "\t- Generalization Loss: 2.199423\n",
      "Loss after iteration 380 -> Train: 0.198652, Validation: 0.245358\n",
      "\t- Generalization Loss: -0.636955\n",
      "Loss after iteration 400 -> Train: 0.198384, Validation: 0.247035\n",
      "\t- Generalization Loss: 0.683498\n",
      "Loss after iteration 420 -> Train: 0.182228, Validation: 0.231629\n",
      "\t- Generalization Loss: -5.595537\n",
      "Loss after iteration 440 -> Train: 0.186389, Validation: 0.237293\n",
      "\t- Generalization Loss: 2.445207\n",
      "Loss after iteration 460 -> Train: 0.172672, Validation: 0.228685\n",
      "\t- Generalization Loss: -1.270846\n",
      "Loss after iteration 480 -> Train: 0.174135, Validation: 0.229583\n",
      "\t- Generalization Loss: 0.392472\n",
      "Loss after iteration 500 -> Train: 0.172359, Validation: 0.233500\n",
      "\t- Generalization Loss: 2.105233\n",
      "Loss after iteration 520 -> Train: 0.164831, Validation: 0.224010\n",
      "\t- Generalization Loss: -2.044250\n",
      "Loss after iteration 540 -> Train: 0.160734, Validation: 0.218765\n",
      "\t- Generalization Loss: -2.341619\n",
      "Loss after iteration 560 -> Train: 0.167359, Validation: 0.228680\n",
      "\t- Generalization Loss: 4.532452\n",
      "Loss after iteration 580 -> Train: 0.157040, Validation: 0.218618\n",
      "\t- Generalization Loss: -0.067083\n",
      "Loss after iteration 600 -> Train: 0.155780, Validation: 0.211050\n",
      "\t- Generalization Loss: -3.461623\n",
      "Loss after iteration 620 -> Train: 0.157772, Validation: 0.214272\n",
      "\t- Generalization Loss: 1.526329\n",
      "Loss after iteration 640 -> Train: 0.152421, Validation: 0.215313\n",
      "\t- Generalization Loss: 2.019598\n",
      "Loss after iteration 660 -> Train: 0.148054, Validation: 0.207585\n",
      "\t- Generalization Loss: -1.641939\n",
      "Loss after iteration 680 -> Train: 0.153743, Validation: 0.215552\n",
      "\t- Generalization Loss: 3.837782\n",
      "Loss after iteration 700 -> Train: 0.148661, Validation: 0.212658\n",
      "\t- Generalization Loss: 2.443865\n",
      "Loss after iteration 720 -> Train: 0.145487, Validation: 0.211840\n",
      "\t- Generalization Loss: 2.049799\n",
      "Loss after iteration 740 -> Train: 0.148043, Validation: 0.211448\n",
      "\t- Generalization Loss: 1.860918\n",
      "Loss after iteration 760 -> Train: 0.139548, Validation: 0.207339\n",
      "\t- Generalization Loss: -0.118631\n",
      "Loss after iteration 780 -> Train: 0.141927, Validation: 0.207762\n",
      "\t- Generalization Loss: 0.203934\n",
      "Loss after iteration 800 -> Train: 0.141333, Validation: 0.214274\n",
      "\t- Generalization Loss: 3.344670\n",
      "Loss after iteration 820 -> Train: 0.142773, Validation: 0.212870\n",
      "\t- Generalization Loss: 2.667904\n",
      "Loss after iteration 840 -> Train: 0.143887, Validation: 0.216637\n",
      "\t- Generalization Loss: 4.484532\n",
      "Loss after iteration 860 -> Train: 0.145229, Validation: 0.218364\n",
      "\t- Generalization Loss: 5.317687\n",
      "Loss after iteration 880 -> Train: 0.142872, Validation: 0.218636\n",
      "\t- Generalization Loss: 5.448771\n",
      "Loss after iteration 900 -> Train: 0.141204, Validation: 0.219409\n",
      "\t- Generalization Loss: 5.821252\n",
      "Loss after iteration 920 -> Train: 0.145160, Validation: 0.222748\n",
      "\t- Generalization Loss: 7.431914\n",
      "Loss after iteration 940 -> Train: 0.137980, Validation: 0.217545\n",
      "\t- Generalization Loss: 4.922701\n",
      "Loss after iteration 960 -> Train: 0.131608, Validation: 0.208855\n",
      "\t- Generalization Loss: 0.731258\n",
      "Loss after iteration 980 -> Train: 0.136200, Validation: 0.218303\n",
      "\t- Generalization Loss: 5.287983\n",
      "Loss after iteration 1000 -> Train: 0.131738, Validation: 0.209478\n",
      "\t- Generalization Loss: 1.031866\n",
      "Loss after iteration 1020 -> Train: 0.136541, Validation: 0.214168\n",
      "\t- Generalization Loss: 3.293596\n",
      "Loss after iteration 1040 -> Train: 0.134739, Validation: 0.216781\n",
      "\t- Generalization Loss: 4.553805\n",
      "Loss after iteration 1060 -> Train: 0.140424, Validation: 0.216508\n",
      "\t- Generalization Loss: 4.422098\n",
      "Loss after iteration 1080 -> Train: 0.135206, Validation: 0.212111\n",
      "\t- Generalization Loss: 2.301495\n",
      "Loss after iteration 1100 -> Train: 0.146169, Validation: 0.228894\n",
      "\t- Generalization Loss: 10.395991\n",
      "Gradient Descent Stopped Early!\n",
      "--- Time: 5495.374988555908 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Now our Network\n",
    "\n",
    "model = {}\n",
    "losses_log = []  #simple list to plot loss over time\n",
    "opt_loss_val = 10000  # init optimum validation set loss to track generalization loss for stopping threshold\n",
    "start_time = time.time()  # track how long gradient descent takes\n",
    "\n",
    "# Gradient descent...\n",
    "# start at 1 instead of 0 for Adam Optimizer - avoids divide by 0\n",
    "for i in range(1, epochs+1):\n",
    "    \n",
    "    mini_batches = get_mini_batches(X_train, y_train, batch_size)\n",
    "    for mb in mini_batches:\n",
    "        X_mb = mb[0]\n",
    "        y_mb = mb[1]\n",
    " \n",
    "        # Forward propagation\n",
    "        # Get DropConnect Mask (0's and 1's in shape of W1)\n",
    "        # This randomly turns weights on and off with some probability\n",
    "        # http://www.matthewzeiler.com/wp-content/uploads/2017/07/icml2013.pdf\n",
    "        dc_mask = drop_connect_mask(drop_connect_prob, W1.shape)\n",
    "        dcW1 = W1 * dc_mask # Apply DropConnect Mask to W1\n",
    "        l1 = activation(X_mb.dot(dcW1) + b1) # Input -> Hidden 1 || activation(x.t * W + bias)\n",
    "        output = softmax(l1.dot(W2) + b2) # Hidden 1 -> Output || Softmax Probabilites\n",
    "\n",
    "        # Backpropagation   \n",
    "        output_error = output - y_mb # technically, you'd need a derived softmax activation, but that equals 1, so we don't add it\n",
    "        l1_error = output_error.dot(W2.T) * activation(l1, True)\n",
    "    \n",
    "        dW2 = np.dot(l1.T, output_error)\n",
    "        db2 = np.average(output_error, axis=0)\n",
    "        dW1 = np.dot(X_mb.T, l1_error)\n",
    "        db1 = np.average(l1_error, axis=0)\n",
    "    \n",
    "        # Apply DropConnect Mask to gradients, so only \"activated\" weights are updated\n",
    "        dW1 = dW1 * dc_mask\n",
    "    \n",
    "        # add regularization terms to weights\n",
    "        dW2 += reg_lambda * W2 \n",
    "        dW1 += reg_lambda * W1\n",
    "        \n",
    "        # Update weights by using Adam Optimization (as opposed to simply learning_rate * gradient)\n",
    "        # https://arxiv.org/pdf/1412.6980.pdf\n",
    "        # http://cs231n.github.io/neural-networks-3/ (See Section: Per-parameter adaptive learning rate methods)\n",
    "        # Update W1\n",
    "        mW1 = beta1*mW1 + (1-beta1)*dW1\n",
    "        mtW1 = mW1 / (1-beta1**i)\n",
    "        vW1 = beta2*vW1 + (1-beta2)*(dW1**2)\n",
    "        vtW1 = vW1 / (1-beta2**i)\n",
    "        W1 += -learning_rate * mtW1 / (np.sqrt(vtW1) + eps)\n",
    "        \n",
    "        # Update W2\n",
    "        mW2 = beta1*mW2 + (1-beta1)*dW2\n",
    "        mtW2 = mW2 / (1-beta1**i)\n",
    "        vW2 = beta2*vW2 + (1-beta2)*(dW2**2)\n",
    "        vtW2 = vW2 / (1-beta2**i)\n",
    "        W2 += -learning_rate * mtW2 / (np.sqrt(vtW2) + eps)\n",
    "\n",
    "        # Update Biases\n",
    "        b1 += -learning_rate * db1 \n",
    "        b2 += -learning_rate * db2\n",
    "    \n",
    "    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "    \n",
    "    # Update Learning Rate\n",
    "    # Theoretically, learning rate decay is already guaranteed by Adam optimizer\n",
    "    # Uncomment this line to use a time-based learning rate decay anyways\n",
    "    #Learning_rate = Learning_rate * 1/(1 + decay * i)\n",
    "    \n",
    "    # Optionally print the loss. \n",
    "    # This is expensive because it uses the whole dataset, so we don't want to do it too often. \n",
    "    if i % print_loss == 0 or i == 1:\n",
    "        loss_train, loss_val = calculate_loss(model)\n",
    "        print(\"Loss after iteration %i -> Train: %f, Validation: %f\" %(i, loss_train, loss_val))\n",
    "        \n",
    "        # Generalization Loss Early Stopping\n",
    "        # This is intuitively \"the percent of generalization we have lost\"\n",
    "        # Section 2.1: http://page.mi.fu-berlin.de/prechelt/Biblio/stop_tricks1997.pdf\n",
    "        generalization_loss = 100 * (loss_val/opt_loss_val - 1)\n",
    "        print(\"\\t- Generalization Loss: %f\" %(generalization_loss))\n",
    "        \n",
    "        losses_log.append([i,loss_train, loss_val, generalization_loss])\n",
    "        \n",
    "        # Check to see if stop early\n",
    "        if generalization_loss > stop_threshold:\n",
    "            print(\"Gradient Descent Stopped Early!\")\n",
    "            break\n",
    "        else:\n",
    "            # update optimal validation loss if better than current optimal\n",
    "            if loss_val < opt_loss_val :\n",
    "                opt_loss_val = loss_val\n",
    "\n",
    "print(\"--- Time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Our Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab our losses\n",
    "\n",
    "iters = []\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "gen_loss = []\n",
    "for ll in losses_log:\n",
    "    iters.append(ll[0])\n",
    "    losses_train.append(ll[1])\n",
    "    losses_val.append(ll[2])\n",
    "    gen_loss.append(ll[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0c19496b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log_loss over time\n",
    "\n",
    "# This gives us a very smooth log_loss plot, which is unusual. Keep that in mind.\n",
    "\n",
    "plt.plot(iters, losses_train, label='Training Loss')\n",
    "plt.plot(iters, losses_val, label='Validation Loss')\n",
    "plt.ylabel('Log_loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.legend(loc=1)\n",
    "plt.title('Log_loss per Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0c194a8cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generalization Loss Over Time\n",
    "\n",
    "plt.plot(iters, gen_loss, label='Generalization Loss')\n",
    "plt.ylabel('Generalization Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.legend(loc=4)\n",
    "plt.title('Generalization Loss per Iteration')\n",
    "plt.axhline(0, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9756333333333334\n",
      "Test Accuracy: 0.969\n"
     ]
    }
   ],
   "source": [
    "# let's see how we did\n",
    "\n",
    "# Forward Propigate to get outputs on train data\n",
    "l1_train = activation(X_train.dot(W1) + b1) # Input -> Hidden 1 || activation(x * W + bias)\n",
    "output_train = softmax(l1_train.dot(W2) + b2)\n",
    "\n",
    "# Forward Propigate to get outputs on test data\n",
    "l1_test = activation(X_test.dot(W1) + b1) # Input -> Hidden 1 || activation(x * W + bias)\n",
    "output_test = softmax(l1_test.dot(W2) + b2) # Hidden 1 -> Output || Softmax Probabilites\n",
    "\n",
    "correct_train = 0\n",
    "for i in range(0, output_train.shape[0]):\n",
    "    if np.argmax(output_train[i]) == np.argmax(y_train[i]):\n",
    "        correct_train += 1\n",
    "\n",
    "correct_test = 0\n",
    "for i in range(0, output_test.shape[0]):\n",
    "    if np.argmax(output_test[i]) == np.argmax(y_test[i]):\n",
    "        correct_test += 1\n",
    "\n",
    "train_accuracy = correct_train / y_train.shape[0]\n",
    "test_accuracy = correct_test / y_test.shape[0]\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
