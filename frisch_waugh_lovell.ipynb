{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frisch–Waugh–Lovell Theorem\n",
    "\n",
    "Causal Inference - Otherwise known as Double ML Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Also sample R code\n",
    "\n",
    "y <- as.numeric(unlist(Boston['medv']))\n",
    "d1 <- as.numeric(unlist(Boston['rm']))\n",
    "d2 <- as.numeric(unlist(Boston['lstat']))\n",
    "X <- as.matrix(Boston[ , !(names(Boston) %in% c(\"medv\",\"lstat\", \"rm\"))])\n",
    "\n",
    "# dependent residuals\n",
    "f <- lm(y ~ X)\n",
    "f_hat = as.numeric(predict(f, as.data.frame(X)))\n",
    "y_res <- y - f_hat\n",
    "\n",
    "# Treatment Residuals\n",
    "g1 <- lm(d1 ~ X)\n",
    "g2 <- lm(d2 ~ X)\n",
    "g1_hat = as.numeric(predict(g1, as.data.frame(d1)))\n",
    "g2_hat = as.numeric(predict(g2, as.data.frame(d2)))\n",
    "d1_res <- d1 - g1_hat\n",
    "d2_res <- d2 - g2_hat\n",
    "\n",
    "# Causal Model\n",
    "# Estimates of Causal Impact are coef\n",
    "summary(lm(y_res ~ d1_res + d2_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.453\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.451\n",
      "Method:                 Least Squares   F-statistic:                              208.9\n",
      "Date:                Mon, 29 Jul 2019   Prob (F-statistic):                    8.61e-67\n",
      "Time:                        22:58:37   Log-Likelihood:                         -1498.8\n",
      "No. Observations:                 506   AIC:                                      3002.\n",
      "Df Residuals:                     504   BIC:                                      3010.\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "RM             3.8099      0.413      9.227      0.000       2.999       4.621\n",
      "LSTAT         -0.5248      0.050    -10.473      0.000      -0.623      -0.426\n",
      "==============================================================================\n",
      "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
      "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
      "Kurtosis:                       8.281   Cond. No.                         9.79\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "RM:\t3.8099 +/- 0.4129\n",
      "LSTAT:\t-0.5248 +/- 0.0501\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "y = dependent variable\n",
    "d = treatment variables\n",
    "X = confounding variables\n",
    "a confounder (also confounding variable, confounding factor, or lurking variable) is a variable that influences both the dependent variable and independent variable, causing a spurious association.\n",
    "'''\n",
    "# Declare treatment variables (what we want to test the causality of)\n",
    "# You should have very few treament variables\n",
    "d1 = X['RM']\n",
    "d2 = X['LSTAT']\n",
    "X = X.drop(['RM', 'LSTAT'], axis=1)\n",
    "\n",
    "# Get Dependent Residuals (\"outcome surprise\")\n",
    "y_hat = LinearRegression().fit(X, y).predict(X)  # This should be best model possible (I'm using LR as an example)\n",
    "y_residual = y - y_hat\n",
    "\n",
    "# Get Treatment Residuals (\"treatment surprise\")\n",
    "d1_hat = LinearRegression().fit(X, d1).predict(X)  # This should be best model possible (I'm using LR as an example)\n",
    "d1_residual = d1 - d1_hat\n",
    "d2_hat = LinearRegression().fit(X, d2).predict(X)  # This should be best model possible (I'm using LR as an example)\n",
    "d2_residual = d2 - d2_hat\n",
    "\n",
    "# Model Causal by modeling the relationalship between dependent and treament residuals\n",
    "# linear weights are your causal estimate\n",
    "d_residual = pd.concat([d1_residual, d2_residual], axis=1)\n",
    "causal_model = sm.OLS(y_residual, d_residual).fit()\n",
    "\n",
    "print(causal_model.summary())\n",
    "print()\n",
    "\n",
    "# Causal Estimate +/- SEM\n",
    "for feature_name, coef, sem in zip(causal_model.params.index.values, causal_model.params, causal_model.bse):\n",
    "    print(f'{feature_name}:\\t{coef:0.4f} +/- {sem:0.4f}')\n",
    "# RM has a higher casual effect than LSTAT\n",
    "# Note: always supply your error with the causal estimate (regression coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
