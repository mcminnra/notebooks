{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde5525e",
   "metadata": {},
   "source": [
    "# Optimization Libraries\n",
    "\n",
    "Mainly looking at them in context of hyper param tuning, but they are general libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4734b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd373117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data\n",
    "\n",
    "data = load_boston()\n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = data['target']\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea49d31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Avg. MSE: 19.4643 (+/- 11.5527)\n"
     ]
    }
   ],
   "source": [
    "# Model we want to optimze\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "print(f' Avg. MSE: {scores.mean()*-1:0.4f} (+/- {scores.std():0.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c20e692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:47<00:00,  1.89trial/s, best loss: 17.8259162028044] \n",
      "{'alpha': 0.7196749905956826, 'lambda': 0.8726803031598735, 'max_depth': 3, 'n_estimators': 420}\n"
     ]
    }
   ],
   "source": [
    "## Hyperopt - Tree-Structured Parzen Estimation / Random Sampling\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "\n",
    "def objective(params):\n",
    "    MAX_DEPTH = params['max_depth']\n",
    "    N_ESTIMATORS = params['n_estimators']\n",
    "    LAMBDA = params['lambda']\n",
    "    ALPHA = params['alpha']\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        max_depth=MAX_DEPTH,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        reg_lambda=LAMBDA,\n",
    "        reg_alpha=ALPHA,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    mse = scores.mean()*-1\n",
    "\n",
    "    return {\n",
    "        'loss': mse,\n",
    "        'status': STATUS_OK,\n",
    "        'params': params\n",
    "    }\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': hp.randint('max_depth', 1, 100),  # Default = 6\n",
    "    'n_estimators': hp.randint('n_estimators', 1, 500),  # Default = 100\n",
    "    'lambda': hp.uniform('lambda', 0, 2),  # Default = 1\n",
    "    'alpha': hp.uniform('alpha', 0, 4),  # Default = 0\n",
    "}\n",
    "\n",
    "trials = Trials()  # allows us to record info from each iteration\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=1000,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(best)\n",
    "# {'alpha': 0.7196749905956826, 'lambda': 0.8726803031598735, 'max_depth': 3, 'n_estimators': 420}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c2fe0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe778fe8c70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's view Lambda (l2 reg)\n",
    "\n",
    "x_chart = [x['result']['params']['lambda'] for x in trials.trials if x['result']['loss'] < 20]\n",
    "y_chart = [x['result']['loss'] for x in trials.trials if x['result']['loss'] < 20]\n",
    "\n",
    "plt.scatter(x_chart, y_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "955bc1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:1 (3.38) best: -18.575845614541482 worst: -25.168145489770904\n",
      "iteration:2 (1.75) best: -18.71881378624962 worst: -25.09893288403287\n",
      "iteration:3 (1.65) best: -18.635818141362176 worst: -23.16358941811586\n",
      "iteration:4 (1.64) best: -18.927997964148865 worst: -23.04058133639911\n",
      "iteration:5 (1.66) best: -18.592041961306922 worst: -23.394284684343653\n",
      "iteration:6 (1.68) best: -18.866826689782208 worst: -23.703412930119875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-c0e4e5998796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mpop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/evol/population.py\u001b[0m in \u001b[0;36mevolve\u001b[0;34m(self, evolution, n)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mCondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevolution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopEvolution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/evol/step.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, population)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBasePopulation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBasePopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/evol/population.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, lazy)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindividual\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mindividual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_documented_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/evol/individual.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_function, lazy)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \"\"\"\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchromosome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutate_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-c0e4e5998796>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 250\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[1;32m    598\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Evol - Genetic Approach\n",
    "\n",
    "from evol import Population, Evolution\n",
    "\n",
    "def population_start():\n",
    "    \"\"\"\n",
    "    Init population with random starting conditions\n",
    "    \"\"\"\n",
    "    max_depth = np.random.randint(low=1, high=100, size=None)\n",
    "    n_estimators = np.random.randint(low=1, high=500, size=None)\n",
    "    reg_lambda = np.random.uniform(low=0.0, high=2.0, size=None)\n",
    "    reg_alpha = np.random.uniform(low=0.0, high=4.0, size=None)\n",
    "    \n",
    "    return max_depth, n_estimators, reg_lambda, reg_alpha\n",
    "\n",
    "def objective(params):\n",
    "    max_depth, n_estimators, reg_lambda, reg_alpha = params\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        reg_lambda=reg_lambda,\n",
    "        reg_alpha=reg_alpha,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    mse = scores.mean()\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "def pick_parents(pop):\n",
    "    \"\"\"\n",
    "    Pick random parents\n",
    "    \"\"\"\n",
    "    mom = np.random.choice(pop, None)\n",
    "    dad = np.random.choice(pop, None)\n",
    "    return mom, dad\n",
    "\n",
    "\n",
    "def make_child(mom, dad):\n",
    "    \"\"\"\n",
    "    This function describes how two candidates combine into a new candidate.\n",
    "    \n",
    "    We'll just take the average of two parents\n",
    "    \"\"\"\n",
    "    child_max_depth = int(np.round((mom[0] + dad[0])/2))\n",
    "    child_n_estimators = int(np.round((mom[1] + dad[1])/2))\n",
    "    child_reg_lambda = (mom[2] + dad[2])/2\n",
    "    child_reg_alpha = (mom[3] + dad[3])/2\n",
    "    \n",
    "    return child_max_depth, child_n_estimators, child_reg_lambda, child_reg_alpha\n",
    "\n",
    "def add_noise(chromosome, sigma):\n",
    "    \"\"\"\n",
    "    This is a function that will add some noise to the chromosome.\n",
    "    \"\"\"\n",
    "    new_max_depth = chromosome[0] + np.random.choice([-1, 0, 1], None) * sigma\n",
    "    new_n_estimators = chromosome[1] + np.random.choice([-1, 0, 1], None) * sigma\n",
    "    new_reg_lambda = chromosome[2] + np.random.choice([-1, 0, 1], None) * (sigma/10)\n",
    "    new_reg_alpha = chromosome[3] + np.random.choice([-1, 0, 1], None) * (sigma/10)\n",
    "    \n",
    "    # check if see if in bounds\n",
    "    new_max_depth = int(new_max_depth) if new_max_depth >= 1 else 1\n",
    "    new_n_estimators = int(new_n_estimators) if new_n_estimators >= 1 else 1\n",
    "    new_reg_lambda = new_reg_lambda if new_reg_lambda >= 0 else 0\n",
    "    new_reg_alpha = new_reg_alpha if new_reg_alpha >= 0 else 0\n",
    "    \n",
    "    return new_max_depth, new_n_estimators, new_reg_lambda, new_reg_alpha\n",
    "\n",
    "# We start by defining a population with candidates.\n",
    "pop = Population(\n",
    "    chromosomes=[population_start() for _ in range(200)],\n",
    "    eval_function=objective,\n",
    "    maximize=True\n",
    ")\n",
    "\n",
    "evo = (\n",
    "    Evolution()\n",
    "    .survive(fraction=0.5)\n",
    "    .breed(parent_picker=pick_parents, combiner=make_child)\n",
    "    .mutate(add_noise, sigma=2)\n",
    "    .evaluate()\n",
    ")\n",
    "\n",
    "for i in range(10):\n",
    "    start = time.time()\n",
    "    pop = pop.evolve(evo)\n",
    "    end = time.time()\n",
    "    delta = end - start\n",
    "    print(f\"iteration:{i+1} ({delta/60:0.2f}) best: {pop.current_best.fitness} worst: {pop.current_worst.fitness}\")\n",
    "    \n",
    "print(pop.current_best.chromosome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
