{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde5525e",
   "metadata": {},
   "source": [
    "# Optimization Libraries\n",
    "\n",
    "Mainly looking at them in context of hyperparameter tuning, but they are general libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4734b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd373117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.03466</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>6.031</td>\n",
       "      <td>23.3</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>362.25</td>\n",
       "      <td>7.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>7.05042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>6.103</td>\n",
       "      <td>85.1</td>\n",
       "      <td>2.0218</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.52</td>\n",
       "      <td>23.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>5.836</td>\n",
       "      <td>91.9</td>\n",
       "      <td>2.2110</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>395.67</td>\n",
       "      <td>18.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.29916</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>5.856</td>\n",
       "      <td>42.1</td>\n",
       "      <td>4.4290</td>\n",
       "      <td>3.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>388.65</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.01501</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>6.635</td>\n",
       "      <td>29.7</td>\n",
       "      <td>8.3440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>390.94</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>11.16040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>6.629</td>\n",
       "      <td>94.6</td>\n",
       "      <td>2.1247</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>109.85</td>\n",
       "      <td>23.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.22876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>6.405</td>\n",
       "      <td>85.4</td>\n",
       "      <td>2.7147</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>70.80</td>\n",
       "      <td>10.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "477  15.02340   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  24.0  666.0   \n",
       "15    0.62739   0.0   8.14   0.0  0.5380  5.834  56.5  4.4986   4.0  307.0   \n",
       "332   0.03466  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407   1.0  304.0   \n",
       "423   7.05042   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  24.0  666.0   \n",
       "19    0.72580   0.0   8.14   0.0  0.5380  5.727  69.5  3.7965   4.0  307.0   \n",
       "..        ...   ...    ...   ...     ...    ...   ...     ...   ...    ...   \n",
       "106   0.17120   0.0   8.56   0.0  0.5200  5.836  91.9  2.2110   5.0  384.0   \n",
       "270   0.29916  20.0   6.96   0.0  0.4640  5.856  42.1  4.4290   3.0  223.0   \n",
       "348   0.01501  80.0   2.01   0.0  0.4350  6.635  29.7  8.3440   4.0  280.0   \n",
       "435  11.16040   0.0  18.10   0.0  0.7400  6.629  94.6  2.1247  24.0  666.0   \n",
       "102   0.22876   0.0   8.56   0.0  0.5200  6.405  85.4  2.7147   5.0  384.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "477     20.2  349.48  24.91  \n",
       "15      21.0  395.62   8.47  \n",
       "332     16.9  362.25   7.83  \n",
       "423     20.2    2.52  23.29  \n",
       "19      21.0  390.95  11.28  \n",
       "..       ...     ...    ...  \n",
       "106     20.9  395.67  18.66  \n",
       "270     18.6  388.65  13.00  \n",
       "348     17.0  390.94   5.99  \n",
       "435     20.2  109.85  23.27  \n",
       "102     20.9   70.80  10.63  \n",
       "\n",
       "[404 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data\n",
    "\n",
    "data = load_boston()\n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea49d31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.560527271813469\n"
     ]
    }
   ],
   "source": [
    "# Model we want to optimze\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c20e692a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:28<00:00, 11.33trial/s, best loss: 4.66249309782992] \n",
      "{'alpha': 2.1777746488708605, 'lambda': 0.3949737375685849, 'max_depth': 50, 'n_estimators': 419}\n"
     ]
    }
   ],
   "source": [
    "## Hyperopt - Tree-Structured Parzen Estimation (Bayesian Estimation)\n",
    "\n",
    "from hyperopt import fmin, hp, tpe, Trials, STATUS_OK\n",
    "\n",
    "def objective(params):\n",
    "    MAX_DEPTH = params['max_depth']\n",
    "    N_ESTIMATORS = params['n_estimators']\n",
    "    LAMBDA = params['lambda']\n",
    "    ALPHA = params['alpha']\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        max_depth=MAX_DEPTH,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        reg_lambda=LAMBDA,\n",
    "        reg_alpha=ALPHA,\n",
    "        verbosity=0,\n",
    "        seed=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return {\n",
    "        'loss': mse,\n",
    "        'status': STATUS_OK,\n",
    "        'params': params\n",
    "    }\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': hp.randint('max_depth', 1, 100),  # Default = 6\n",
    "    'n_estimators': hp.randint('n_estimators', 1, 500),  # Default = 100\n",
    "    'lambda': hp.uniform('lambda', 0, 2),  # Default = 1\n",
    "    'alpha': hp.uniform('alpha', 0, 4),  # Default = 0\n",
    "}\n",
    "\n",
    "trials = Trials()  # allows us to record info from each iteration\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=1000,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(best)\n",
    "# {'alpha': 0.7196749905956826, 'lambda': 0.8726803031598735, 'max_depth': 3, 'n_estimators': 420}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c2fe0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff977006130>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's view Lambda (l2 reg)\n",
    "\n",
    "x_chart = [x['result']['params']['lambda'] for x in trials.trials if x['result']['loss'] < 20]\n",
    "y_chart = [x['result']['loss'] for x in trials.trials if x['result']['loss'] < 20]\n",
    "\n",
    "plt.scatter(x_chart, y_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "955bc1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:1 (0.60) best: 4.539701602799563 worst: 10.038962710000352\n",
      "(5, 103, 0.170694929987536, 0.2067268846744308)\n",
      "iteration:2 (0.26) best: 4.829596472336706 worst: 8.628398210251838\n",
      "(7, 59, 0.17188259278154028, 3.9739111660591013)\n",
      "iteration:3 (0.28) best: 4.54766154963563 worst: 8.795063818649647\n",
      "(49, 199, 0.179220855289429, 1.2051638047195405)\n",
      "iteration:4 (0.24) best: 4.54766154963563 worst: 8.439148418831751\n",
      "(49, 199, 0.179220855289429, 1.2051638047195405)\n",
      "iteration:5 (0.25) best: 4.4963828948743085 worst: 8.042608473726155\n",
      "(65, 169, 0.044912198482116694, 1.616958454170358)\n",
      "iteration:6 (0.26) best: 4.54766154963563 worst: 8.029691108917476\n",
      "(49, 199, 0.179220855289429, 1.2051638047195405)\n",
      "iteration:7 (0.25) best: 4.581245217280008 worst: 8.093425777182812\n",
      "(46, 183, 0.0, 0.9939520349784583)\n",
      "iteration:8 (0.24) best: 4.5803741518467875 worst: 8.81246462998012\n",
      "(63, 210, 0, 0.9637249887426494)\n",
      "iteration:9 (0.24) best: 4.568507318347185 worst: 7.77228766794448\n",
      "(48, 206, 0, 2.5330769877079904)\n",
      "iteration:10 (0.23) best: 4.541981059494776 worst: 8.349188363360307\n",
      "(48, 233, 0, 0.9826503408762226)\n"
     ]
    }
   ],
   "source": [
    "## Evol - Genetic Approach\n",
    "\n",
    "from evol import Population, Evolution\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def population_start():\n",
    "    \"\"\"\n",
    "    Init population with random starting conditions\n",
    "    \"\"\"\n",
    "    max_depth = np.random.randint(low=1, high=100, size=None)\n",
    "    n_estimators = np.random.randint(low=1, high=500, size=None)\n",
    "    reg_lambda = np.random.uniform(low=0.0, high=2.0, size=None)\n",
    "    reg_alpha = np.random.uniform(low=0.0, high=4.0, size=None)\n",
    "    \n",
    "    return max_depth, n_estimators, reg_lambda, reg_alpha\n",
    "\n",
    "def objective(params):\n",
    "    max_depth, n_estimators, reg_lambda, reg_alpha = params\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        reg_lambda=reg_lambda,\n",
    "        reg_alpha=reg_alpha,\n",
    "        verbosity=0,\n",
    "        seed=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "def pick_parents(pop):\n",
    "    \"\"\"\n",
    "    Pick random parents\n",
    "    \"\"\"\n",
    "    mom = np.random.choice(pop, None)\n",
    "    dad = np.random.choice(pop, None)\n",
    "    return mom, dad\n",
    "\n",
    "\n",
    "def make_child(mom, dad):\n",
    "    \"\"\"\n",
    "    This function describes how two candidates combine into a new candidate.\n",
    "    \n",
    "    We'll just take the average of two parents\n",
    "    \"\"\"\n",
    "    child_max_depth = int(np.round((mom[0] + dad[0])/2))\n",
    "    child_n_estimators = int(np.round((mom[1] + dad[1])/2))\n",
    "    child_reg_lambda = (mom[2] + dad[2])/2\n",
    "    child_reg_alpha = (mom[3] + dad[3])/2\n",
    "    \n",
    "    return child_max_depth, child_n_estimators, child_reg_lambda, child_reg_alpha\n",
    "\n",
    "def add_noise(chromosome, sigma):\n",
    "    \"\"\"\n",
    "    This is a function that will add some noise to the chromosome.\n",
    "    \"\"\"\n",
    "    new_max_depth = chromosome[0] + np.random.choice([-1, 1], None) * sigma\n",
    "    new_n_estimators = chromosome[1] + np.random.choice([-1, 1], None) * sigma\n",
    "    new_reg_lambda = chromosome[2] + (np.random.random_sample()-0.5) * sigma\n",
    "    new_reg_alpha = chromosome[3] + (np.random.random_sample()-0.5) * sigma\n",
    "    \n",
    "    # check if see if in bounds\n",
    "    new_max_depth = int(new_max_depth) if new_max_depth >= 1 else 1\n",
    "    new_n_estimators = int(new_n_estimators) if new_n_estimators >= 1 else 1\n",
    "    new_reg_lambda = new_reg_lambda if new_reg_lambda >= 0 else 0\n",
    "    new_reg_alpha = new_reg_alpha if new_reg_alpha >= 0 else 0\n",
    "    \n",
    "    return new_max_depth, new_n_estimators, new_reg_lambda, new_reg_alpha\n",
    "\n",
    "# We start by defining a population with candidates.\n",
    "pop = Population(\n",
    "    chromosomes=[population_start() for _ in range(200)],\n",
    "    eval_function=objective,\n",
    "    maximize=False\n",
    ")\n",
    "\n",
    "evo = (\n",
    "    Evolution()\n",
    "    .survive(fraction=0.5)\n",
    "    .breed(parent_picker=pick_parents, combiner=make_child)\n",
    "    .mutate(add_noise, probability=0.5, elitist=True, sigma=1)\n",
    "    .evaluate()\n",
    ")\n",
    "\n",
    "for i in range(10):\n",
    "    start = time.time()\n",
    "    pop = pop.evolve(evo)\n",
    "    end = time.time()\n",
    "    delta = end - start\n",
    "    \n",
    "    print(f\"iteration:{i+1} ({delta/60:0.2f}) best: {pop.current_best.fitness} worst: {pop.current_worst.fitness}\")\n",
    "    print(pop.current_best.chromosome)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
